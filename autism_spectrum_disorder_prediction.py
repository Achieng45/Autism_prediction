# -*- coding: utf-8 -*-
"""Autism_Spectrum_Disorder_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1y-IxpqlO80_al-AJBcKS3-33CJkDH1I7
"""
import pickle

import matplotlib.pyplot as plt
import matplotlib as mlp
import numpy as np
import pandas as pd
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler,StandardScaler,LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix

asd=pd.read_csv('Autism_prediction\Autism Spectrum Disorder Screening Data for Toddlers in Saudi Arabia Data Set.csv')

"""Data Preprocessing and conversion to numerical values"""

#Family member with ASD history	
asd['Family member with ASD history']= asd['Family member with ASD history'].replace(['Yes'],1)
asd['Family member with ASD history']= asd['Family member with ASD history'].replace(['No'],0)

#Gender
asd['Gender']= asd['Gender'].replace(['Female'],0)
asd['Gender']= asd['Gender'].replace(['Male'],1)

#region
#asd['Region']=asd['Region'].str.strip() 
asd['Region']= asd['Region'].replace(["Riyadh Province"],1)
asd['Region']= asd['Region'].replace(["Makkah Province"],2)
asd['Region']= asd['Region'].replace(["Madinah Province"],3)
asd['Region']= asd['Region'].replace(["Qassim Province"],4)
asd['Region']= asd['Region'].replace(["Eastern Province"],5)
asd['Region']= asd['Region'].replace(["Aseer Province"],6)
asd['Region']= asd['Region'].replace(["Tabuk Province"],7)
asd['Region']= asd['Region'].replace(["Ha'il Province"],8)
asd['Region']= asd['Region'].replace(["Northern Borders Province"],9)
asd['Region']= asd['Region'].replace(["Jizan Province"],10)
asd['Region']= asd['Region'].replace(["Najran Province"],11)
asd['Region']= asd['Region'].replace(["Al Baha Province"],12)
asd['Region']= asd['Region'].replace(["Al Jawf Province"],13)

#drop unused attributes
asd=asd.drop(columns=['Who is completing the test','Screening Score'])
asd

asd.describe

font = {'family' : 'normal',
        'weight' : 'normal',
        'size'   : 30}
corr = asd.corr()
plt.figure(figsize =(60,60))
sns.heatmap(data = corr, annot = True, square = True, cbar = True)

scaler=MinMaxScaler()
scaler.fit(asd[['Age']])
asd['Age']=scaler.transform(asd[['Age']])

#split data into features and target
X = asd.iloc[:,0:14]
y = asd.iloc[:, 14:15]

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.8,test_size=0.2,stratify=y,shuffle=True, random_state=1)

"""Feature selection using CHI square"""

#split data into features and target
df = pd.DataFrame(asd)
X = df.iloc[:,0:14]
y = df.iloc[:, 14:15]
y = y.values.ravel()
feature_name=X.columns

"""Feature selection using CHI-SQUARE"""

from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2
from sklearn.preprocessing import MinMaxScaler

f=6 #number of top feature to select 
chi_selector = SelectKBest(chi2, k=f)
chi_selector.fit(X, y)
chi_support = chi_selector.get_support()
chi_feature = X.loc[:,chi_support].columns.tolist()
print(str(len(chi_feature)), 'selected features')
print(chi_feature)

#feature selection using Mutual Information(MI)	
from sklearn.feature_selection import mutual_info_classif

ML = SelectKBest(score_func=mutual_info_classif,k=f)
ML.fit(X, y)
ML_ = ML.get_support()
ML_F = X.loc[:,ML_].columns.tolist()
print(str(len(ML_F)), 'selected features')
print(ML_F)

# put all selection together
feature_selection_df = pd.DataFrame({'Feature':feature_name, 'Chi-square':chi_support,'Mutual Information(MI)':ML_})
# count the selected times for each feature
feature_selection_df['Total'] = np.sum(feature_selection_df, axis=1)
# display 
feature_selection_df = feature_selection_df.sort_values(['Total','Feature'] , ascending=False)
feature_selection_df.index = range(1, len(feature_selection_df)+1)
feature_selection_df.head(14)

#AFTER FEATURE SELECTION
#drop
X_n=X.drop(columns=['Gender','Region','Family member with ASD history','Age','A7','A5','A10','A1'])
#split
X_train_f, X_test_f, y_train_f, y_test_f = train_test_split(X_n, y, train_size=0.8, test_size=0.20,stratify=y,random_state=1)

y_train_f=y_train_f.ravel()

from sklearn.ensemble import RandomForestClassifier
RFC_model_AFS=RandomForestClassifier(n_estimators=100)
RFC_model_AFS.fit(X_train_f,y_train_f)

"""
Prediction

"""

RFC_predict=RFC_model_AFS.predict(X_test_f)
from sklearn.metrics import classification_report, confusion_matrix
print(classification_report(y_test_f,RFC_predict))

from seaborn.algorithms import bootstrap
#number of trees
n_estimators = [ int(X) for X in np.linspace(start=10,stop=80,num=10)]
#number of features to consider at every split
max_features = ['auto', 'sqrt']
#maximum number of levels in tree
max_depth = [2,4]
#minimum number of samples required to split a node
min_samples_split = [2, 5]
#minimum samples required at each leaf node
min_samples_leaf = [1, 2] 
#method of selecting samples
bootstrap=[True,False]

param_grid = {
    'n_estimators':n_estimators,
    'max_features':max_features,
    'max_depth':max_depth,
    'min_samples_split':min_samples_split,
    'min_samples_leaf':min_samples_leaf,
    'bootstrap':bootstrap
    
}
print(param_grid)

rf_Model=RandomForestClassifier()

"""GridSearch CV"""

from sklearn.model_selection import GridSearchCV
rf_grid=GridSearchCV(estimator=rf_Model,param_grid=param_grid,cv=10,verbose=2,n_jobs=4)
rf_grid.fit(X_train_f,y_train_f)

rf_grid.best_params_

rf_grid_search=rf_grid.predict(X_test_f)
print(classification_report(y_test_f,rf_grid_search))

from sklearn.model_selection import RandomizedSearchCV
rf_RandomGrid=RandomizedSearchCV(estimator=rf_Model,param_distributions=param_grid,cv=10,verbose=2,n_jobs=4)
rf_RandomGrid.fit(X_train_f,y_train_f)

rf_RandomGrid.best_params_

rf_random_grid=rf_RandomGrid.predict(X_test_f)
print(classification_report(y_test_f,rf_random_grid))

print(f'Train Accuracy - :{rf_grid.score(X_train_f,y_train_f):.3f}')
print(f'Test Accuracy-:{rf_grid.score(X_test_f,y_test_f):.3f}')

print(f'Train Accuracy - :{rf_RandomGrid.score(X_train_f,y_train_f):.3f}')
print(f'Test Accuracy-:{rf_RandomGrid.score(X_test_f,y_test_f):.3f}')
"""
pickle.dump(rf_RandomGrid, open("model.pkl","wb"))
"""
with open('model.pkl','wb') as file:
    pickle.dump(rf_RandomGrid,file)